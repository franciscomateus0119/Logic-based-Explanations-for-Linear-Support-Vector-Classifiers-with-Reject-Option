{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e8b514-4fef-41f3-b3ac-7483d2970d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install anchor-exp\n",
    "#!pip install pulp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53035e6d-87d7-47c8-bc06-4d169b7c7909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anchor import utils\n",
    "from anchor import anchor_tabular\n",
    "from pulp import *\n",
    "from pulp import LpProblem, LpVariable, LpMinimize, LpInteger, lpSum, value, LpBinary,LpStatusOptimal\n",
    "import pulp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Overwriting previously set objective.\")\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import svm_explainer\n",
    "import utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fcc08c-b55c-4dbf-9e66-b4815409bce7",
   "metadata": {
    "id": "PW90CcDBHbaM"
   },
   "outputs": [],
   "source": [
    "dataset = datasets.load_wine()\n",
    "dataset_name = 'Wine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5952206-3fd7-4636-89ec-88e61cfb5702",
   "metadata": {
    "id": "q5plsclR7tUW"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(dataset.data)\n",
    "normalized_df = scaler.transform(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa2d6f3-445f-47a7-8d13-dd2891c6bb73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMHNARKC8KJR",
    "outputId": "bbe60b5e-fc61-4253-dfb8-75efb51dfe0a"
   },
   "outputs": [],
   "source": [
    "lower_bound = normalized_df.min()\n",
    "upper_bound = normalized_df.max()\n",
    "print(normalized_df.min(),normalized_df.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacdb0ea-e608-487f-a207-eb3cd8a64696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = utility.check_targets(np.where(dataset.target == dataset.target[0],0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29c6a96-f261-4650-84ec-260b47b2e9e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dx90Sjfwh9cz",
    "outputId": "565c216c-c6e3-48bf-a20b-c64f577ab7f1"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(normalized_df, targets, test_size=0.3,random_state=107,stratify=targets)\n",
    "X = np.concatenate((X_train,X_test),axis=0)\n",
    "y = np.concatenate((y_train,y_test),axis=0)\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "#Train the models using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy Linear:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "y_pred_train = clf.predict(X_train)\n",
    "print(\"Accuracy on Training:\", metrics.accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "y_ = clf.predict(X)\n",
    "print(\"Accuracy on Total:\", metrics.accuracy_score(y_, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6112c601-23f6-4b81-a73d-1f598952143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Thresholds by minimizing the empiric risk\n",
    "threshold_upper,threshold_lower = utility.find_thresholds(clf, X_train, y_train, wr=[0.24])\n",
    "\n",
    "#Labeling patterns based on found thresholds\n",
    "positive_indexes,negative_indexes,rejected_indexes = utility.find_indexes(clf, X, threshold_upper,threshold_lower)\n",
    "print(f\"Positive patterns = {len(positive_indexes)},\\nNegative patterns = {len(negative_indexes)},\\nRejected patterns = {len(rejected_indexes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac3eef-b546-4d09-8a9e-134814287c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "test_accuracy = utility.calculate_accuracy(clf, threshold_upper, threshold_lower, X_test, y_test)\n",
    "print(f\"Test Accuracy = {test_accuracy}\")\n",
    "\n",
    "train_accuracy = utility.calculate_accuracy(clf, threshold_upper, threshold_lower, X_train, y_train)\n",
    "print(f\"Train Accuracy = {train_accuracy}\")\n",
    "\n",
    "all_accuracy = utility.calculate_accuracy(clf, threshold_upper, threshold_lower, X, y)\n",
    "print(f\"All Accuracy = {all_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79d0a88-b1a9-4c59-826b-ffc0141145ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Anchors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a031d075-161f-42b5-a54e-50b5659f54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ro_target_set(target_set,rejected_indexes):\n",
    "    target_set[rejected_indexes] = 0\n",
    "    return target_set\n",
    "def svm_decfun(data,classifier=clf):\n",
    "    return ((classifier.dual_coef_ @ classifier.support_vectors_) @ data.T + classifier.intercept_)[0][0]\n",
    "def svm_decfun_class(data,classifier=clf,Threshold_1=threshold_upper,Threshold_2=threshold_lower):\n",
    "    if svm_decfun(data) > Threshold_1:\n",
    "        return np.array([2]) #class 1, since [-1, 0, 1]\n",
    "    elif svm_decfun(data) < Threshold_2:\n",
    "        return np.array([0]) #class -1\n",
    "    else:\n",
    "        return np.array([1]) #class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e501ff2-3122-414b-a36c-7063a329459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro_set = generate_ro_target_set(y,rejected_indexes)\n",
    "ro_set = y\n",
    "print(np.unique(ro_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4877fa26-bec1-49b4-be0b-79237e0e6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "for i in range(0,len(X[0])):\n",
    "    feature_list.append(str(i))\n",
    "feature_list = np.array(feature_list)\n",
    "\n",
    "explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "    [-1,0,1],\n",
    "    feature_list,\n",
    "    X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b468331-d3c4-42ae-b3e9-2a70c1c973c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Time and Size Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d9275-275c-43d8-a16d-c192cc9e611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_columns_names = ['Anchors', 'COIN_CBC', 'Class']\n",
    "times_df  = pd.DataFrame(columns=times_columns_names)\n",
    "\n",
    "sizes_columns_names = ['Anchors', 'COIN_CBC', 'Class']\n",
    "sizes_df  = pd.DataFrame(columns=sizes_columns_names)\n",
    "\n",
    "pulp_all_times = []\n",
    "pulp_all_sizes = []\n",
    "anchors_all_times = []\n",
    "anchors_all_sizes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b04e284-c757-40cb-b7b2-4ef4d96c26f8",
   "metadata": {},
   "source": [
    "# Time and Size Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8241de-a595-4418-8332-d819c3d47ffd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Singular Sample - Negative Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0029dc12-f228-48de-ae04-7fa53d0b538d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_sizes = []\n",
    "anchors_explanation = []\n",
    "complete_explanations = []\n",
    "anchors_times = []\n",
    "if len(negative_indexes) > 0:\n",
    "    for idx in negative_indexes:\n",
    "        start = time.perf_counter()\n",
    "        explainer.class_names[svm_decfun_class(np.atleast_2d(X[idx]))[0]]  \n",
    "        exp = explainer.explain_instance(X[idx], svm_decfun_class, threshold=1)\n",
    "        end = time.perf_counter()\n",
    "        anchors_times.append(end - start)\n",
    "        complete_explanations.append(exp.names())\n",
    "        feature_sizes.append(len((exp.names())))\n",
    "        anchors_explanation.append(exp.features())\n",
    "    print(f\"Anchors Explanation Time Mean: {np.mean(np.asarray(anchors_times))}\")\n",
    "    print(f\"Anchors Explanation Size Mean: {np.mean(np.asarray(feature_sizes))}\")\n",
    "anchors_all_times.append(anchors_times)\n",
    "anchors_all_sizes.append(feature_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6998a5-fad6-45fd-819f-9d3f8d5a8830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pulp_times = []\n",
    "pulp_explanations = []\n",
    "pulp_sizes = []\n",
    "for idx in negative_indexes:\n",
    "    start = time.perf_counter()\n",
    "    pulp_exp = svm_explainer.svm_explanation_binary(\n",
    "                                    \n",
    "                                    dual_coef = clf.dual_coef_,\n",
    "                                    support_vectors = clf.support_vectors_,\n",
    "                                    intercept = clf.intercept_,\n",
    "                                    data = np.atleast_2d(X[idx]),\n",
    "                                    \n",
    "                                    t_lower = threshold_lower,\n",
    "                                    t_upper = threshold_upper,\n",
    "                                    lower_bound = lower_bound,\n",
    "                                    upper_bound = upper_bound,\n",
    "                                    show_log = 0,\n",
    "                                    classified = \"Negative\",\n",
    "                                    validate = False)\n",
    "    end = time.perf_counter()\n",
    "    pulp_times.append((end - start))\n",
    "    \n",
    "    pulp_explanations.append(pulp_exp[-1])\n",
    "    pulp_sizes.append(len(pulp_exp[-1]))\n",
    "print(f\"Pulp COIN CBC Time Mean: {np.mean(np.asarray(pulp_times))}\")\n",
    "frequency = utility.detail_explanation(explanations = pulp_explanations, patterns = X[negative_indexes], number_of_features = len(X[0]), show_explanation = False)\n",
    "print(f\"Pulp COIN CBC Explanation Mean: {frequency.values.sum() / len(frequency)} feature rules\")\n",
    "pulp_all_times.append(pulp_times)\n",
    "pulp_all_sizes.append(pulp_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc418f2-55b7-4bda-a47c-dcfd8ae19111",
   "metadata": {},
   "outputs": [],
   "source": [
    "for anch_time, pulp_time in zip(anchors_times, pulp_times):\n",
    "    pattern_row = [anch_time, pulp_time,'Negative']\n",
    "    times_df.loc[len(times_df), :] = pattern_row\n",
    "for anch_size, pulp_size in zip(feature_sizes, pulp_sizes):\n",
    "    pattern_row = [anch_size, pulp_size,'Negative']\n",
    "    sizes_df.loc[len(sizes_df), :] = pattern_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf9172-4351-4189-8ddb-dbc37086058c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Singular Sample - Positive Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842b3684-13f3-4ee3-a198-e326737119bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_sizes = []\n",
    "anchors_explanation = []\n",
    "complete_explanations = []\n",
    "anchors_times = []\n",
    "if len(positive_indexes) > 0:\n",
    "    for idx in positive_indexes:\n",
    "        start = time.perf_counter()\n",
    "        explainer.class_names[svm_decfun_class(np.atleast_2d(X[idx]))[0]]  \n",
    "        exp = explainer.explain_instance(X[idx], svm_decfun_class, threshold=1)\n",
    "        end = time.perf_counter()\n",
    "        anchors_times.append(end - start)\n",
    "        complete_explanations.append(exp.names())\n",
    "        feature_sizes.append(len((exp.names())))\n",
    "        anchors_explanation.append(exp.features())\n",
    "    print(f\"Anchors Explanation Time Mean: {np.mean(np.asarray(anchors_times))}\")\n",
    "    print(f\"Anchors Explanation Size Mean: {np.mean(np.asarray(feature_sizes))}\")\n",
    "anchors_all_times.append(anchors_times)\n",
    "anchors_all_sizes.append(feature_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d88225-41fc-4ec1-89d0-682c6ca6fd39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pulp_times = []\n",
    "pulp_explanations = []\n",
    "pulp_sizes = []\n",
    "for idx in positive_indexes:\n",
    "    start = time.perf_counter()\n",
    "    pulp_exp = svm_explainer.svm_explanation_binary(\n",
    "                                    \n",
    "                                    dual_coef = clf.dual_coef_,\n",
    "                                    support_vectors = clf.support_vectors_,\n",
    "                                    intercept = clf.intercept_,\n",
    "                                    data = np.atleast_2d(X[idx]),\n",
    "                                    \n",
    "                                    t_lower = threshold_lower,\n",
    "                                    t_upper = threshold_upper,\n",
    "                                    lower_bound = lower_bound,\n",
    "                                    upper_bound = upper_bound,\n",
    "                                    show_log = 0,\n",
    "                                    classified = \"Positive\",\n",
    "                                    validate = False)\n",
    "    end = time.perf_counter()\n",
    "    pulp_times.append((end - start))\n",
    "    \n",
    "    pulp_explanations.append(pulp_exp[-1])\n",
    "    pulp_sizes.append(len(pulp_exp[-1]))\n",
    "print(f\"Pulp COIN CBC Time Mean: {np.mean(np.asarray(pulp_times))}\")\n",
    "frequency = utility.detail_explanation(explanations = pulp_explanations, patterns = X[positive_indexes], number_of_features = len(X[0]), show_explanation = False)\n",
    "print(f\"Pulp COIN CBC Explanation Mean: {frequency.values.sum() / len(frequency)} feature rules\")\n",
    "pulp_all_times.append(pulp_times)\n",
    "pulp_all_sizes.append(pulp_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e37b93c-d2fc-4725-a9db-2e7848be78e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for anch_time, pulp_time in zip(anchors_times, pulp_times):\n",
    "    pattern_row = [anch_time, pulp_time,'Positive']\n",
    "    times_df.loc[len(times_df), :] = pattern_row\n",
    "for anch_size, pulp_size in zip(feature_sizes, pulp_sizes):\n",
    "    pattern_row = [anch_size, pulp_size,'Positive']\n",
    "    sizes_df.loc[len(sizes_df), :] = pattern_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd36beb3-fdaa-4ff4-87db-33541942c0a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Singular Sample - Rejected Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe64dc9-5438-4eab-a9c7-b09ec4aee44c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_sizes = []\n",
    "anchors_explanation = []\n",
    "complete_explanations = []\n",
    "anchors_times = []\n",
    "if len(rejected_indexes) > 0:\n",
    "    for idx in rejected_indexes:\n",
    "        start = time.perf_counter()\n",
    "        explainer.class_names[svm_decfun_class(np.atleast_2d(X[idx]))[0]]\n",
    "        exp = explainer.explain_instance(X[idx], svm_decfun_class, threshold=1)\n",
    "        end = time.perf_counter()\n",
    "        anchors_times.append(end - start)\n",
    "        complete_explanations.append(exp.names())\n",
    "        feature_sizes.append(len((exp.names())))\n",
    "        anchors_explanation.append(exp.features())\n",
    "    print(f\"Anchors Explanation Time Mean: {np.mean(np.asarray(anchors_times))}\")\n",
    "    print(f\"Anchors Explanation Size Mean: {np.mean(np.asarray(feature_sizes))}\")\n",
    "anchors_all_times.append(anchors_times)\n",
    "anchors_all_sizes.append(feature_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa0942-aab0-4035-9ceb-7ad6a33a4833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pulp_times = []\n",
    "pulp_explanations = []\n",
    "pulp_sizes = []\n",
    "if len(rejected_indexes) > 0:\n",
    "    for idx in rejected_indexes:\n",
    "        start = time.perf_counter()\n",
    "        pulp_exp = svm_explainer.svm_explanation_rejected(\n",
    "                                    \n",
    "                                    dual_coef = clf.dual_coef_,\n",
    "                                    support_vectors = clf.support_vectors_,\n",
    "                                    intercept = clf.intercept_,\n",
    "                                    t_lower = threshold_lower,\n",
    "                                    t_upper = threshold_upper,\n",
    "                                    lower_bound = lower_bound,\n",
    "                                    upper_bound = upper_bound,\n",
    "                                    data = np.atleast_2d(X[idx]),\n",
    "                                    show_log = 0,\n",
    "                                    validate = False)\n",
    "        end = time.perf_counter()\n",
    "        pulp_times.append((end - start))\n",
    "\n",
    "        pulp_explanations.append(pulp_exp[-1])\n",
    "        pulp_sizes.append(len(pulp_exp[-1]))\n",
    "    print(f\"Pulp COIN CBC Time Mean: {np.mean(np.asarray(pulp_times))}\")\n",
    "    frequency = utility.detail_explanation(explanations = pulp_explanations, patterns = X[rejected_indexes], number_of_features = len(X[0]), show_explanation = False)\n",
    "    print(f\"Pulp COIN CBC Explanation Mean: {frequency.values.sum() / len(frequency)} feature rules\")\n",
    "    pulp_all_times.append(pulp_times)\n",
    "    pulp_all_sizes.append(pulp_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540e2ae-ea78-4c91-be09-2a2ad410e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for anch_time, pulp_time in zip(anchors_times, pulp_times):\n",
    "    pattern_row = [anch_time, pulp_time,'Rejected']\n",
    "    times_df.loc[len(times_df), :] = pattern_row\n",
    "\n",
    "for anch_size, pulp_size in zip(feature_sizes, pulp_sizes):\n",
    "    pattern_row = [anch_size, pulp_size,'Rejected']\n",
    "    sizes_df.loc[len(sizes_df), :] = pattern_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8cf276-a717-48d7-96a0-44e688bff305",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde2ce71-39e7-487e-bd29-39f3979b355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors_negative_time = None\n",
    "anchors_positive_time = None\n",
    "anchors_rejected_time = None\n",
    "if len(negative_indexes) >0:\n",
    "    anchors_negative_time = sum(anchors_all_times[0])/len(anchors_all_times[0])\n",
    "    \n",
    "if len(positive_indexes) >0:\n",
    "    anchors_positive_time = sum(anchors_all_times[1])/len(anchors_all_times[1])\n",
    "\n",
    "if len(rejected_indexes) >0:\n",
    "    anchors_rejected_time = sum(anchors_all_times[2])/len(anchors_all_times[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec1dd3-9c52-4e5d-a4cf-f5dd6c4eae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_multiple_columns_names = ['Anchors_Mean', 'COIN_CBC_Single_Mean', 'Class']\n",
    "times_multiple_df  = pd.DataFrame(columns=times_multiple_columns_names)\n",
    "pattern_row = [anchors_negative_time, sum(pulp_all_times[0])/len(pulp_all_times[0]),'Negative']\n",
    "times_multiple_df.loc[len(times_multiple_df), :] = pattern_row\n",
    "\n",
    "pattern_row = [anchors_positive_time, sum(pulp_all_times[1])/len(pulp_all_times[1]), 'Positive']\n",
    "times_multiple_df.loc[len(times_multiple_df), :] = pattern_row\n",
    "\n",
    "if len(rejected_indexes) > 0:\n",
    "    pattern_row = [anchors_rejected_time, sum(pulp_all_times[2])/len(pulp_all_times[2]), 'Rejected']\n",
    "    times_multiple_df.loc[len(times_multiple_df), :] = pattern_row\n",
    "display(times_multiple_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea69a03-7690-492a-9ce6-9b7bd6a655b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes_mean_names = ['Anchors_Mean', 'COIN_CBC_Mean', 'Class']\n",
    "sizes_mean_df  = pd.DataFrame(columns=sizes_mean_names)\n",
    "classes = ['Negative', 'Positive', 'Rejected']\n",
    "if len(rejected_indexes) > 0:\n",
    "    for i in range(3):\n",
    "        pattern_row = [sum(anchors_all_sizes[i])/len(anchors_all_sizes[i]), sum(pulp_all_sizes[i])/len(pulp_all_sizes[i]), classes[i]]\n",
    "        sizes_mean_df.loc[len(sizes_mean_df), :] = pattern_row\n",
    "else:\n",
    "    for i in range(2):\n",
    "        pattern_row = [sum(anchors_all_sizes[i])/len(anchors_all_sizes[i]), sum(pulp_all_sizes[i])/len(pulp_all_sizes[i]), classes[i]]\n",
    "        sizes_mean_df.loc[len(sizes_mean_df), :] = pattern_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f4761-9d18-4a37-9086-5d1f23c510f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sizes_mean_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9591d989-a699-48ef-88de-007a4316ff6f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
