{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44515baa-f342-404e-963d-81dfb5a8d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pulp import *\n",
    "from pulp import LpProblem, LpVariable, LpMinimize, LpInteger, lpSum, value, LpBinary,LpStatusOptimal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Overwriting previously set objective.\")\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import svm_explainer\n",
    "import utility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bebcde-3ea6-4ec8-b00c-5dd09c8ba180",
   "metadata": {},
   "source": [
    "# Dataset loading and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7021a2ae-5d94-4a88-bb77-2d6c9634de04",
   "metadata": {
    "id": "PW90CcDBHbaM"
   },
   "outputs": [],
   "source": [
    "#Iris Dataset - 4 Features\n",
    "dataset = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff351e6-088b-4739-ad1c-08138eed73db",
   "metadata": {
    "id": "q5plsclR7tUW"
   },
   "outputs": [],
   "source": [
    "#Scaling dataset features\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(dataset.data)\n",
    "scaled_df = scaler.transform(dataset.data)\n",
    "print(scaled_df.min(),scaled_df.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d91153-76f1-4964-8a43-694a4464cdb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Changing the patterns to follow a [-1, 1] pattern.\n",
    "targets = utility.check_targets(np.where(dataset.target == dataset.target[0],0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189cbcb1-465c-42bc-9c82-d14cd4875f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into train/test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, targets, test_size=0.3,random_state=107, stratify=targets)\n",
    "X = np.concatenate((X_train,X_test),axis=0)\n",
    "y = np.concatenate((y_train,y_test),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31551352-59ad-401c-9d9b-0bc6d7c94ef4",
   "metadata": {},
   "source": [
    "# Training the Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d0bf90-316d-48e6-a8f9-daf3b6bbdfc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dx90Sjfwh9cz",
    "outputId": "565c216c-c6e3-48bf-a20b-c64f577ab7f1"
   },
   "outputs": [],
   "source": [
    "#Training the model using the training set\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict for test set\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy Linear:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "y_pred_train = clf.predict(X_train)\n",
    "print(\"Accuracy on Training:\", metrics.accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "y_ = clf.predict(X)\n",
    "print(\"Accuracy on All:\", metrics.accuracy_score(y_, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5c71dc-3eee-4fa5-89f8-49fc1846b2d2",
   "metadata": {},
   "source": [
    "# Generating Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f914871-4ea8-455c-a55a-b6e9f9c202b5",
   "metadata": {},
   "source": [
    "## Finding Thresholds and Labeling Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b645dbb7-27d4-4f32-88b0-1f5e0ef35b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Thresholds by minimizing the empiric risk\n",
    "threshold_upper,threshold_lower = utility.find_thresholds(clf, X_train, y_train, wr=[0.24])\n",
    "\n",
    "#Accuracy on Test data\n",
    "test_accuracy = utility.calculate_accuracy(clf, threshold_upper, threshold_lower, X_test, y_test)\n",
    "print(f\"Test Accuracy = {test_accuracy}\")\n",
    "\n",
    "train_accuracy = utility.calculate_accuracy(clf, threshold_upper, threshold_lower, X_train, y_train)\n",
    "print(f\"Train Accuracy = {train_accuracy}\")\n",
    "\n",
    "all_accuracy = utility.calculate_accuracy(clf, threshold_upper, threshold_lower, X, y)\n",
    "print(f\"All Accuracy = {train_accuracy}\")\n",
    "\n",
    "#Labeling patterns based on found thresholds\n",
    "positive_indexes,negative_indexes,rejected_indexes = utility.find_indexes(clf, X, threshold_upper,threshold_lower)\n",
    "print(f\"Positive patterns = {len(positive_indexes)},\\nNegative patterns = {len(negative_indexes)},\\nRejected patterns = {len(rejected_indexes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a38f0e-7b2d-402d-af06-dce848fc8898",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Explanations for Rejected Class Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f78f5-a59d-459c-98c9-124cabf9cd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(rejected_indexes) > 0:\n",
    "    explanation = explainer.svm_explanation_rejected(\n",
    "                                    dual_coef = clf.dual_coef_,\n",
    "                                    support_vectors = clf.support_vectors_,\n",
    "                                    intercept = clf.intercept_,\n",
    "                                    t_lower = threshold_lower,\n",
    "                                    t_upper = threshold_upper,\n",
    "                                    lower_bound = scaled_df.min(),\n",
    "                                    upper_bound = scaled_df.max(),\n",
    "                                    data = X[rejected_indexes],\n",
    "                                    show_log = 0,\n",
    "                                    n_threads = 4)\n",
    "    utility.detail_explanation(explanations = explanation, patterns = X[rejected_indexes], number_of_features = len(X[0]), feature_names = dataset.feature_names, show_explanation = True)\n",
    "    print(\"Mean size of explanation: \", sum([(len(explanation[i])) for i in range(len(explanation))])/len(explanation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e1451c-b9b5-4bf1-a917-c40eda0e4c0d",
   "metadata": {},
   "source": [
    "## Explanations for Negative Class Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8640c2-f204-49b8-8083-d01fa86d04ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(negative_indexes) > 0:\n",
    "    explanation = svm_explainer.svm_explanation_binary(\n",
    "                                    dual_coef = clf.dual_coef_,\n",
    "                                    support_vectors = clf.support_vectors_,\n",
    "                                    intercept = clf.intercept_,\n",
    "                                    t_lower = threshold_lower,\n",
    "                                    t_upper = threshold_upper,\n",
    "                                    lower_bound = scaled_df.min(),\n",
    "                                    upper_bound = scaled_df.max(),\n",
    "                                    show_log = 0,\n",
    "                                    n_threads = 4,\n",
    "                                    data = X[negative_indexes],\n",
    "                                    classified = \"Negative\")\n",
    "    utility.detail_explanation(explanations = explanation, patterns = X[negative_indexes], number_of_features = len(X[0]), feature_names = dataset.feature_names, show_explanation = True)\n",
    "    print(\"Mean size of explanation: \", sum([(len(explanation[i])) for i in range(len(explanation))])/len(explanation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2484cf-35f0-428c-846b-e165b68efcb4",
   "metadata": {},
   "source": [
    "## Explanations for Positive Class Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b634a1e5-9a4d-4594-aa0d-68207f4f5ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(positive_indexes) > 0:\n",
    "    explanation = svm_explainer.svm_explanation_binary(\n",
    "                                    dual_coef = clf.dual_coef_,\n",
    "                                    support_vectors = clf.support_vectors_,\n",
    "                                    intercept = clf.intercept_,\n",
    "                                    t_lower = threshold_lower,\n",
    "                                    t_upper = threshold_upper,\n",
    "                                    lower_bound = scaled_df.min(),\n",
    "                                    upper_bound = scaled_df.max(),\n",
    "                                    show_log = 0,\n",
    "                                    n_threads = 4,\n",
    "                                    data = X[positive_indexes],\n",
    "                                    classified = \"Positive\")\n",
    "    utility.detail_explanation(explanations = explanation, patterns = X[positive_indexes], number_of_features = len(X[0]), show_explanation = True)\n",
    "    print(\"Mean size of explanation: \", sum([(len(explanation[i])) for i in range(len(explanation))])/len(explanation))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
